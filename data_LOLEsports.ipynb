{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_data(df):\n",
    "    # Drop columns: 'gameid', 'datacompleteness' and 50 other columns\n",
    "    df = df.drop(columns=['gameid', 'datacompleteness', 'url', 'league', 'split', 'year', 'playoffs', 'date', 'game', 'patch', 'participantid', 'side', 'teamid', 'champion', 'ban1', 'ban2', 'ban3', 'ban4', 'ban5', 'gamelength', 'doublekills', 'triplekills', 'quadrakills', 'pentakills', 'firstbloodassist', 'firstbloodkill', 'firstbloodvictim', 'firstdragon', 'dragons', 'opp_dragons', 'elementaldrakes', 'infernals', 'opp_elementaldrakes', 'mountains', 'clouds', 'oceans', 'chemtechs', 'hextechs', 'dragons (type unknown)', 'elders', 'opp_elders', 'firstherald', 'heralds', 'opp_heralds', 'firstbaron', 'firsttower', 'towers', 'opp_towers', 'firstmidtower', 'firsttothreetowers', 'turretplates', 'opp_turretplates'])\n",
    "    # Drop rows with missing data in columns: 'playername', 'result'\n",
    "    df = df.dropna(subset=['playername', 'result'])\n",
    "    # Drop column: 'gspd'\n",
    "    df = df.drop(columns=['gspd'])\n",
    "    # Drop column: 'monsterkillsenemyjungle'\n",
    "    df = df.drop(columns=['monsterkillsenemyjungle'])\n",
    "    # Drop column: 'monsterkillsownjungle'\n",
    "    df = df.drop(columns=['monsterkillsownjungle'])\n",
    "    # Drop rows with missing data across all columns\n",
    "    df = df.dropna()\n",
    "    # Drop column: 'playerid'\n",
    "    df = df.drop(columns=['playerid'])\n",
    "    # Export DataFrame to an Excel file\n",
    "    df.to_excel(\"output.xlsx\", index=False)\n",
    "    return df\n",
    "\n",
    "# Loaded variable 'df' from URI: c:\\Users\\ssjed\\OneDrive\\Documents\\GitHub\\Fall2024\\STAT 335\\Final\\2024_LoL_esports_match_data_from_OraclesElixir.xlsx\n",
    "df = pd.read_excel(r'c:\\Users\\ssjed\\OneDrive\\Documents\\GitHub\\Fall2024\\STAT 335\\Final\\2024_LoL_esports_match_data_from_OraclesElixir.xlsx')\n",
    "\n",
    "df_clean = clean_data(df.copy())\n",
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_df_clean = df_clean.select_dtypes(include=['number'])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numeric_df_clean.corr()\n",
    "\n",
    "# Get the absolute values of the correlation matrix\n",
    "abs_correlation_matrix = correlation_matrix.abs()\n",
    "\n",
    "# Unstack the matrix and sort by correlation value\n",
    "sorted_correlations = abs_correlation_matrix.unstack().sort_values(ascending=False)\n",
    "\n",
    "# Drop the duplicate pairs (correlation of a variable with itself)\n",
    "sorted_correlations = sorted_correlations[sorted_correlations != 1]\n",
    "\n",
    "# Display the sorted correlations\n",
    "sorted_correlations\n",
    "\n",
    "# Calculate the correlation of 'result' with all other columns\n",
    "result_correlations = abs_correlation_matrix['result']\n",
    "\n",
    "# Sort the correlations by absolute value in descending order\n",
    "sorted_result_correlations = result_correlations.sort_values(ascending=False)\n",
    "\n",
    "# Display the sorted correlations\n",
    "sorted_result_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_df_clean = df_clean.select_dtypes(include=['number'])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numeric_df_clean.corr()\n",
    "\n",
    "# Get the absolute values of the correlation matrix\n",
    "abs_correlation_matrix = correlation_matrix.abs()\n",
    "\n",
    "# Unstack the matrix and sort by correlation value\n",
    "sorted_correlations = abs_correlation_matrix.unstack().sort_values(ascending=False)\n",
    "\n",
    "# Drop the duplicate pairs (correlation of a variable with itself)\n",
    "sorted_correlations = sorted_correlations[sorted_correlations != 1]\n",
    "\n",
    "# Display the sorted correlations\n",
    "sorted_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets based on position\n",
    "positions = ['top', 'jng', 'mid', 'bot', 'sup']\n",
    "datasets = {}\n",
    "\n",
    "for position in positions:\n",
    "    datasets[position] = df_clean[df_clean['position'] == position]\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "for position, dataset in datasets.items():\n",
    "    print(f\"Dataset for position: {position}\")\n",
    "    print(dataset.head())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN ON FIRST TIME ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean_teams = df_clean.sort_values(['teamname'], ascending=[False])\n",
    "# df_clean_teams.head()\n",
    "# df_clean_teams.to_excel(\"teams.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Create an Excel file for each role\n",
    "# for position, dataset in datasets.items():\n",
    "#     filename = f\"{position}_dataset.xlsx\"\n",
    "#     dataset.to_excel(filename, index=False)\n",
    "#     print(f\"Created {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN ON FIRST TIME ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the 'roles' directory if it doesn't exist\n",
    "# if not os.path.exists('roles'):\n",
    "#     os.makedirs('roles')\n",
    "\n",
    "# # Move the Excel files to the 'roles' directory\n",
    "# for position, dataset in datasets.items():\n",
    "#     filename = f\"{position}_dataset.xlsx\"\n",
    "#     destination = os.path.join('roles', filename)\n",
    "#     if os.path.exists(destination):\n",
    "#         os.remove(destination)\n",
    "#     os.rename(filename, destination)\n",
    "#     print(f\"Moved {filename} to roles/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features = numeric_df_clean.drop(columns=['result'])\n",
    "target = numeric_df_clean['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=8334)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Add a constant to the features\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "\n",
    "# Fit the initial model with all features\n",
    "model = sm.Logit(y_train, X_train_const).fit()\n",
    "\n",
    "# Perform backward selection\n",
    "def backward_selection(data, target, significance_level=0.05):\n",
    "    features = data.columns.tolist()\n",
    "    while len(features) > 0:\n",
    "        X = sm.add_constant(data[features])\n",
    "        model = sm.Logit(target, X).fit(disp=0)\n",
    "        p_values = model.pvalues[1:]  # Exclude the intercept\n",
    "        max_p_value = p_values.max()\n",
    "        if max_p_value > significance_level:\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else:\n",
    "            break\n",
    "    return features\n",
    "\n",
    "# Run backward selection\n",
    "selected_features = backward_selection(X_train, y_train)\n",
    "\n",
    "# Fit the final model with selected features\n",
    "X_train_selected = sm.add_constant(X_train[selected_features])\n",
    "final_model = sm.Logit(y_train, X_train_selected).fit()\n",
    "\n",
    "# Evaluate the final model\n",
    "X_test_selected = sm.add_constant(X_test[selected_features])\n",
    "y_pred = final_model.predict(X_test_selected)\n",
    "y_pred_class = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_class)\n",
    "report = classification_report(y_test, y_pred_class)\n",
    "\n",
    "print(f'Selected Features: {selected_features}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the teams dataset\n",
    "df_teams = pd.read_excel(\"teams.xlsx\")\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_df_teams = df_teams.select_dtypes(include=['number'])\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features_teams = numeric_df_teams.drop(columns=['result'])\n",
    "target_teams = numeric_df_teams['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_teams, X_test_teams, y_train_teams, y_test_teams = train_test_split(features_teams, target_teams, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model_teams = LogisticRegression(max_iter=8334)\n",
    "model_teams.fit(X_train_teams, y_train_teams)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_teams = model_teams.predict(X_test_teams)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_teams = accuracy_score(y_test_teams, y_pred_teams)\n",
    "report_teams = classification_report(y_test_teams, y_pred_teams)\n",
    "\n",
    "print(f'Accuracy: {accuracy_teams}')\n",
    "print('Classification Report:')\n",
    "print(report_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backward selection for the teams dataset\n",
    "selected_features_teams = backward_selection(features_teams, target_teams)\n",
    "\n",
    "# Fit the final model with selected features\n",
    "X_train_teams_selected = sm.add_constant(X_train_teams[selected_features_teams])\n",
    "final_model_teams = sm.Logit(y_train_teams, X_train_teams_selected).fit()\n",
    "\n",
    "# Evaluate the final model\n",
    "X_test_teams_selected = sm.add_constant(X_test_teams[selected_features_teams])\n",
    "y_pred_teams_selected = final_model_teams.predict(X_test_teams_selected)\n",
    "y_pred_teams_class = (y_pred_teams_selected > 0.5).astype(int)\n",
    "\n",
    "accuracy_teams_selected = accuracy_score(y_test_teams, y_pred_teams_class)\n",
    "report_teams_selected = classification_report(y_test_teams, y_pred_teams_class)\n",
    "\n",
    "print(f'Selected Features: {selected_features_teams}')\n",
    "print(f'Accuracy: {accuracy_teams_selected}')\n",
    "print('Classification Report:')\n",
    "print(report_teams_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Iterate through each dataset in the roles folder\n",
    "for position, dataset in datasets.items():\n",
    "    # Select only numeric columns\n",
    "    numeric_dataset = dataset.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Define the feature columns and target variable\n",
    "    features = numeric_dataset.drop(columns=['result'])\n",
    "    target = numeric_dataset['result']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create and train the logistic regression model\n",
    "    model = LogisticRegression(max_iter=8334)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f'Position: {position}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print('Classification Report:')\n",
    "    print(report)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the best models and their summaries for each role\n",
    "best_models = {}\n",
    "\n",
    "# Iterate through each dataset in the roles folder\n",
    "for position, dataset in datasets.items():\n",
    "    # Select only numeric columns\n",
    "    numeric_dataset = dataset.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Define the feature columns and target variable\n",
    "    features = numeric_dataset.drop(columns=['result'])\n",
    "    target = numeric_dataset['result']\n",
    "    \n",
    "    # Run backward selection\n",
    "    selected_features = backward_selection(features, target)\n",
    "    \n",
    "    # Fit the final model with selected features\n",
    "    X_train_selected = sm.add_constant(features[selected_features])\n",
    "    final_model = sm.Logit(target, X_train_selected).fit()\n",
    "    \n",
    "    # Save the selected features and model summary\n",
    "    best_models[position] = {\n",
    "        'selected_features': selected_features,\n",
    "        'model_summary': final_model.summary()\n",
    "    }\n",
    "    \n",
    "    # Display the selected features and model summary\n",
    "    print(f'Position: {position}')\n",
    "    print(f'Selected Features: {selected_features}')\n",
    "    print(final_model.summary())\n",
    "    print('\\n')\n",
    "\n",
    "# Display the best models and their summaries for each role\n",
    "for position, model_info in best_models.items():\n",
    "    print(f'Position: {position}')\n",
    "    print(f'Selected Features: {model_info[\"selected_features\"]}')\n",
    "    print(model_info['model_summary'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features = numeric_df_clean.drop(columns=['result'])\n",
    "target = numeric_df_clean['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "log_accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {log_accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Function to perform backward selection\n",
    "def backward_selection_rf(X_train, y_train, X_test, y_test, significance_level=0.05):\n",
    "    features = X_train.columns.tolist()\n",
    "    best_accuracy = 0\n",
    "    best_features = features.copy()\n",
    "    \n",
    "    while len(features) > 0:\n",
    "        # Train the Random Forest model\n",
    "        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf_model.fit(X_train[features], y_train)\n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        y_pred = rf_model.predict(X_test[features])\n",
    "        \n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_features = features.copy()\n",
    "        \n",
    "        # Get feature importances\n",
    "        importances = rf_model.feature_importances_\n",
    "        \n",
    "        # Find the least important feature\n",
    "        least_important_feature = features[np.argmin(importances)]\n",
    "        \n",
    "        # Remove the least important feature\n",
    "        features.remove(least_important_feature)\n",
    "    \n",
    "    return best_features, best_accuracy\n",
    "\n",
    "# Run backward selection\n",
    "selected_features_rf, best_accuracy_rf = backward_selection_rf(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Fit the final Random Forest model with selected features\n",
    "rf_model_final = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_final.fit(X_train[selected_features_rf], y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf_final = rf_model_final.predict(X_test[selected_features_rf])\n",
    "\n",
    "# Evaluate the final model\n",
    "accuracy_rf_final = accuracy_score(y_test, y_pred_rf_final)\n",
    "report_rf_final = classification_report(y_test, y_pred_rf_final)\n",
    "\n",
    "print(f'Selected Features: {selected_features_rf}')\n",
    "print(f'Best Accuracy: {best_accuracy_rf}')\n",
    "print('Final Model Accuracy:', accuracy_rf_final)\n",
    "print('Classification Report:')\n",
    "print(report_rf_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features_teams = numeric_df_teams.drop(columns=['result'])\n",
    "target_teams = numeric_df_teams['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_teams, X_test_teams, y_train_teams, y_test_teams = train_test_split(features_teams, target_teams, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "rf_model_teams = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_teams.fit(X_train_teams, y_train_teams)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_teams = rf_model_teams.predict(X_test_teams)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_teams = accuracy_score(y_test_teams, y_pred_teams)\n",
    "report_teams = classification_report(y_test_teams, y_pred_teams)\n",
    "\n",
    "print(f'Accuracy: {accuracy_teams}')\n",
    "print('Classification Report:')\n",
    "print(report_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backward selection for the teams dataset using Random Forest\n",
    "selected_features_rf_teams, best_accuracy_rf_teams = backward_selection_rf(X_train_teams, y_train_teams, X_test_teams, y_test_teams)\n",
    "\n",
    "# Fit the final Random Forest model with selected features\n",
    "rf_model_final_teams = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_final_teams.fit(X_train_teams[selected_features_rf_teams], y_train_teams)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf_final_teams = rf_model_final_teams.predict(X_test_teams[selected_features_rf_teams])\n",
    "\n",
    "# Evaluate the final model\n",
    "accuracy_rf_final_teams = accuracy_score(y_test_teams, y_pred_rf_final_teams)\n",
    "report_rf_final_teams = classification_report(y_test_teams, y_pred_rf_final_teams)\n",
    "\n",
    "print(f'Selected Features: {selected_features_rf_teams}')\n",
    "print(f'Best Accuracy: {best_accuracy_rf_teams}')\n",
    "print('Final Model Accuracy:', accuracy_rf_final_teams)\n",
    "print('Classification Report:')\n",
    "print(report_rf_final_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Iterate through each dataset in the roles folder\n",
    "for position, dataset in datasets.items():\n",
    "    # Select only numeric columns\n",
    "    numeric_dataset = dataset.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Define the feature columns and target variable\n",
    "    features = numeric_dataset.drop(columns=['result'])\n",
    "    target = numeric_dataset['result']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create and train the Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f'Position: {position}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print('Classification Report:')\n",
    "    print(report)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the best models and their accuracies for each role\n",
    "best_models_rf = {}\n",
    "\n",
    "# Iterate through each dataset in the roles folder\n",
    "for position, dataset in datasets.items():\n",
    "    # Select only numeric columns\n",
    "    numeric_dataset = dataset.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Define the feature columns and target variable\n",
    "    features = numeric_dataset.drop(columns=['result'])\n",
    "    target = numeric_dataset['result']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Run backward selection\n",
    "    selected_features_rf, best_accuracy_rf = backward_selection_rf(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # Fit the final Random Forest model with selected features\n",
    "    rf_model_final = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model_final.fit(X_train[selected_features_rf], y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred_rf_final = rf_model_final.predict(X_test[selected_features_rf])\n",
    "    \n",
    "    # Evaluate the final model\n",
    "    accuracy_rf_final = accuracy_score(y_test, y_pred_rf_final)\n",
    "    report_rf_final = classification_report(y_test, y_pred_rf_final)\n",
    "    \n",
    "    # Save the best model and its accuracy\n",
    "    best_models_rf[position] = {\n",
    "        'selected_features': selected_features_rf,\n",
    "        'best_accuracy': best_accuracy_rf,\n",
    "        'final_model_accuracy': accuracy_rf_final,\n",
    "        'classification_report': report_rf_final\n",
    "    }\n",
    "    \n",
    "    print(f'Position: {position}')\n",
    "    print(f'Selected Features: {selected_features_rf}')\n",
    "    print(f'Best Accuracy: {best_accuracy_rf}')\n",
    "    print('Final Model Accuracy:', accuracy_rf_final)\n",
    "    print('Classification Report:')\n",
    "    print(report_rf_final)\n",
    "    print('\\n')\n",
    "\n",
    "# Display the best models and their accuracies for each role\n",
    "for position, model_info in best_models_rf.items():\n",
    "    print(f'Position: {position}')\n",
    "    print(f'Selected Features: {model_info[\"selected_features\"]}')\n",
    "    print(f'Best Accuracy: {model_info[\"best_accuracy\"]}')\n",
    "    print(f'Final Model Accuracy: {model_info[\"final_model_accuracy\"]}')\n",
    "    print('Classification Report:')\n",
    "    print(model_info['classification_report'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features = numeric_df_clean.drop(columns=['result'])\n",
    "target = numeric_df_clean['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the LASSO regression model\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "# Evaluate the LASSO model\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "print(f'LASSO Regression Mean Squared Error: {mse_lasso}')\n",
    "\n",
    "# Create and train the Ridge regression model\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Ridge model\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "print(f'Ridge Regression Mean Squared Error: {mse_ridge}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features_teams = numeric_df_teams.drop(columns=['result'])\n",
    "target_teams = numeric_df_teams['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_teams, X_test_teams, y_train_teams, y_test_teams = train_test_split(features_teams, target_teams, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the LASSO regression model\n",
    "lasso_model_teams = Lasso(alpha=0.1)\n",
    "lasso_model_teams.fit(X_train_teams, y_train_teams)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lasso_teams = lasso_model_teams.predict(X_test_teams)\n",
    "\n",
    "# Evaluate the LASSO model\n",
    "mse_lasso_teams = mean_squared_error(y_test_teams, y_pred_lasso_teams)\n",
    "print(f'LASSO Regression Mean Squared Error for Teams: {mse_lasso_teams}')\n",
    "\n",
    "# Create and train the Ridge regression model\n",
    "ridge_model_teams = Ridge(alpha=1.0)\n",
    "ridge_model_teams.fit(X_train_teams, y_train_teams)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_ridge_teams = ridge_model_teams.predict(X_test_teams)\n",
    "\n",
    "# Evaluate the Ridge model\n",
    "mse_ridge_teams = mean_squared_error(y_test_teams, y_pred_ridge_teams)\n",
    "print(f'Ridge Regression Mean Squared Error for Teams: {mse_ridge_teams}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Iterate through each dataset in the roles folder\n",
    "for position, dataset in datasets.items():\n",
    "    # Select only numeric columns\n",
    "    numeric_dataset = dataset.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Define the feature columns and target variable\n",
    "    features = numeric_dataset.drop(columns=['result'])\n",
    "    target = numeric_dataset['result']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create and train the LASSO regression model\n",
    "    lasso_model = Lasso(alpha=0.1)\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred_lasso = lasso_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the LASSO model\n",
    "    mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "    \n",
    "    # Create and train the Ridge regression model\n",
    "    ridge_model = Ridge(alpha=1.0)\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred_ridge = ridge_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the Ridge model\n",
    "    mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "    \n",
    "    print(f'Position: {position}')\n",
    "    print(f'LASSO Regression Mean Squared Error: {mse_lasso}')\n",
    "    print(f'Ridge Regression Mean Squared Error: {mse_ridge}')\n",
    "    print('\\n')\n",
    "    # Save the models and their mean squared errors\n",
    "    best_models[position] = {\n",
    "        'lasso_model': lasso_model,\n",
    "        'ridge_model': ridge_model,\n",
    "        'mse_lasso': mse_lasso,\n",
    "        'mse_ridge': mse_ridge\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features = numeric_df_clean.drop(columns=['result'])\n",
    "target = numeric_df_clean['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "report_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "print(f'Accuracy: {accuracy_knn}')\n",
    "print('Classification Report:')\n",
    "print(report_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to perform backward selection\n",
    "def backward_selection_knn(X_train, y_train, X_test, y_test, significance_level=0.05):\n",
    "    features = X_train.columns.tolist()\n",
    "    best_accuracy = 0\n",
    "    best_features = features.copy()\n",
    "    \n",
    "    while len(features) > 0:\n",
    "        # Train the KNN model\n",
    "        knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "        knn_model.fit(X_train[features], y_train)\n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        y_pred = knn_model.predict(X_test[features])\n",
    "        \n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_features = features.copy()\n",
    "        \n",
    "        # Calculate feature importances (using permutation importance)\n",
    "        importances = []\n",
    "        for feature in features:\n",
    "            X_test_permuted = X_test.copy()\n",
    "            X_test_permuted[feature] = np.random.permutation(X_test[feature])\n",
    "            y_pred_permuted = knn_model.predict(X_test_permuted[features])\n",
    "            permuted_accuracy = accuracy_score(y_test, y_pred_permuted)\n",
    "            importances.append(best_accuracy - permuted_accuracy)\n",
    "        \n",
    "        # Find the least important feature\n",
    "        least_important_feature = features[np.argmin(importances)]\n",
    "        \n",
    "        # Remove the least important feature\n",
    "        features.remove(least_important_feature)\n",
    "    \n",
    "    return best_features, best_accuracy\n",
    "\n",
    "# Run backward selection\n",
    "selected_features_knn, best_accuracy_knn = backward_selection_knn(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Fit the final KNN model with selected features\n",
    "knn_model_final = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model_final.fit(X_train[selected_features_knn], y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_knn_final = knn_model_final.predict(X_test[selected_features_knn])\n",
    "\n",
    "# Evaluate the final model\n",
    "accuracy_knn_final = accuracy_score(y_test, y_pred_knn_final)\n",
    "report_knn_final = classification_report(y_test, y_pred_knn_final)\n",
    "\n",
    "print(f'Selected Features: {selected_features_knn}')\n",
    "print(f'Best Accuracy: {best_accuracy_knn}')\n",
    "print('Final Model Accuracy:', accuracy_knn_final)\n",
    "print('Classification Report:')\n",
    "print(report_knn_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features_teams = numeric_df_teams.drop(columns=['result'])\n",
    "target_teams = numeric_df_teams['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_teams, X_test_teams, y_train_teams, y_test_teams = train_test_split(features_teams, target_teams, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the KNN model\n",
    "knn_model_teams = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model_teams.fit(X_train_teams, y_train_teams)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_teams_knn = knn_model_teams.predict(X_test_teams)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_teams_knn = accuracy_score(y_test_teams, y_pred_teams_knn)\n",
    "report_teams_knn = classification_report(y_test_teams, y_pred_teams_knn)\n",
    "\n",
    "print(f'Accuracy: {accuracy_teams_knn}')\n",
    "print('Classification Report:')\n",
    "print(report_teams_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backward selection for the teams dataset using KNN\n",
    "selected_features_knn_teams, best_accuracy_knn_teams = backward_selection_knn(X_train_teams, y_train_teams, X_test_teams, y_test_teams)\n",
    "\n",
    "# Fit the final KNN model with selected features\n",
    "knn_model_final_teams = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model_final_teams.fit(X_train_teams[selected_features_knn_teams], y_train_teams)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_knn_final_teams = knn_model_final_teams.predict(X_test_teams[selected_features_knn_teams])\n",
    "\n",
    "# Evaluate the final model\n",
    "accuracy_knn_final_teams = accuracy_score(y_test_teams, y_pred_knn_final_teams)\n",
    "report_knn_final_teams = classification_report(y_test_teams, y_pred_knn_final_teams)\n",
    "\n",
    "print(f'Selected Features: {selected_features_knn_teams}')\n",
    "print(f'Best Accuracy: {best_accuracy_knn_teams}')\n",
    "print('Final Model Accuracy:', accuracy_knn_final_teams)\n",
    "print('Classification Report:')\n",
    "print(report_knn_final_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Iterate through each dataset in the roles folder\n",
    "for position, dataset in datasets.items():\n",
    "    # Select only numeric columns\n",
    "    numeric_dataset = dataset.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Define the feature columns and target variable\n",
    "    features = numeric_dataset.drop(columns=['result'])\n",
    "    target = numeric_dataset['result']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create and train the KNN model\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f'Position: {position}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print('Classification Report:')\n",
    "    print(report)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the best models and their accuracies for each role\n",
    "best_models_knn = {}\n",
    "\n",
    "# Iterate through each dataset in the roles folder\n",
    "for position, dataset in datasets.items():\n",
    "    # Select only numeric columns\n",
    "    numeric_dataset = dataset.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Define the feature columns and target variable\n",
    "    features = numeric_dataset.drop(columns=['result'])\n",
    "    target = numeric_dataset['result']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Run backward selection\n",
    "    selected_features_knn, best_accuracy_knn = backward_selection_knn(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # Fit the final KNN model with selected features\n",
    "    knn_model_final = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_model_final.fit(X_train[selected_features_knn], y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred_knn_final = knn_model_final.predict(X_test[selected_features_knn])\n",
    "    \n",
    "    # Evaluate the final model\n",
    "    accuracy_knn_final = accuracy_score(y_test, y_pred_knn_final)\n",
    "    report_knn_final = classification_report(y_test, y_pred_knn_final)\n",
    "    \n",
    "    # Save the best model and its accuracy\n",
    "    best_models_knn[position] = {\n",
    "        'selected_features': selected_features_knn,\n",
    "        'best_accuracy': best_accuracy_knn,\n",
    "        'final_model_accuracy': accuracy_knn_final,\n",
    "        'classification_report': report_knn_final\n",
    "    }\n",
    "    \n",
    "    print(f'Position: {position}')\n",
    "    print(f'Selected Features: {selected_features_knn}')\n",
    "    print(f'Best Accuracy: {best_accuracy_knn}')\n",
    "    print('Final Model Accuracy:', accuracy_knn_final)\n",
    "    print('Classification Report:')\n",
    "    print(report_knn_final)\n",
    "    print('\\n')\n",
    "\n",
    "# Display the best models and their accuracies for each role\n",
    "for position, model_info in best_models_knn.items():\n",
    "    print(f'Position: {position}')\n",
    "    print(f'Selected Features: {model_info[\"selected_features\"]}')\n",
    "    print(f'Best Accuracy: {model_info[\"best_accuracy\"]}')\n",
    "    print(f'Final Model Accuracy: {model_info[\"final_model_accuracy\"]}')\n",
    "    print('Classification Report:')\n",
    "    print(model_info['classification_report'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features = numeric_df_clean.drop(columns=['result'])\n",
    "target = numeric_df_clean['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Function to perform backward selection\n",
    "def backward_selection_nn(X_train, y_train, X_test, y_test, significance_level=0.05):\n",
    "    features = X_train.columns.tolist()\n",
    "    best_accuracy = 0\n",
    "    best_features = features.copy()\n",
    "    \n",
    "    while len(features) > 0:\n",
    "        # Standardize the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train[features])\n",
    "        X_test_scaled = scaler.transform(X_test[features])\n",
    "        \n",
    "        # Create the neural network model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        y_pred_prob = model.predict(X_test_scaled)\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_features = features.copy()\n",
    "        \n",
    "        # Calculate feature importances (using permutation importance)\n",
    "        importances = []\n",
    "        for feature in features:\n",
    "            X_test_permuted = X_test.copy()\n",
    "            X_test_permuted[feature] = np.random.permutation(X_test[feature])\n",
    "            X_test_permuted_scaled = scaler.transform(X_test_permuted[features])\n",
    "            y_pred_permuted_prob = model.predict(X_test_permuted_scaled)\n",
    "            y_pred_permuted = (y_pred_permuted_prob > 0.5).astype(int)\n",
    "            permuted_accuracy = accuracy_score(y_test, y_pred_permuted)\n",
    "            importances.append(best_accuracy - permuted_accuracy)\n",
    "        \n",
    "        # Find the least important feature\n",
    "        least_important_feature = features[np.argmin(importances)]\n",
    "        \n",
    "        # Remove the least important feature\n",
    "        features.remove(least_important_feature)\n",
    "    \n",
    "    return best_features, best_accuracy\n",
    "\n",
    "# Run backward selection\n",
    "selected_features_nn, best_accuracy_nn = backward_selection_nn(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Fit the final neural network model with selected features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_selected = scaler.fit_transform(X_train[selected_features_nn])\n",
    "X_test_scaled_selected = scaler.transform(X_test[selected_features_nn])\n",
    "\n",
    "model_final_nn = Sequential()\n",
    "model_final_nn.add(Dense(64, input_dim=X_train_scaled_selected.shape[1], activation='relu'))\n",
    "model_final_nn.add(Dense(32, activation='relu'))\n",
    "model_final_nn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_final_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_final_nn.fit(X_train_scaled_selected, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_prob_final_nn = model_final_nn.predict(X_test_scaled_selected)\n",
    "y_pred_final_nn = (y_pred_prob_final_nn > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the final model\n",
    "accuracy_final_nn = accuracy_score(y_test, y_pred_final_nn)\n",
    "report_final_nn = classification_report(y_test, y_pred_final_nn)\n",
    "\n",
    "print(f'Selected Features: {selected_features_nn}')\n",
    "print(f'Best Accuracy: {best_accuracy_nn}')\n",
    "print('Final Model Accuracy:', accuracy_final_nn)\n",
    "print('Classification Report:')\n",
    "print(report_final_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features_teams = numeric_df_teams.drop(columns=['result'])\n",
    "target_teams = numeric_df_teams['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_teams, X_test_teams, y_train_teams, y_test_teams = train_test_split(features_teams, target_teams, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler_teams = StandardScaler()\n",
    "X_train_teams_scaled = scaler_teams.fit_transform(X_train_teams)\n",
    "X_test_teams_scaled = scaler_teams.transform(X_test_teams)\n",
    "\n",
    "# Create the neural network model\n",
    "model_teams_nn = Sequential()\n",
    "model_teams_nn.add(Dense(64, input_dim=X_train_teams_scaled.shape[1], activation='relu'))\n",
    "model_teams_nn.add(Dense(32, activation='relu'))\n",
    "model_teams_nn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_teams_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_teams_nn.fit(X_train_teams_scaled, y_train_teams, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_teams_prob_nn = model_teams_nn.predict(X_test_teams_scaled)\n",
    "y_pred_teams_nn = (y_pred_teams_prob_nn > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_teams_nn = accuracy_score(y_test_teams, y_pred_teams_nn)\n",
    "report_teams_nn = classification_report(y_test_teams, y_pred_teams_nn)\n",
    "\n",
    "print(f'Accuracy: {accuracy_teams_nn}')\n",
    "print('Classification Report:')\n",
    "print(report_teams_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backward selection for the teams dataset using neural network\n",
    "selected_features_nn_teams, best_accuracy_nn_teams = backward_selection_nn(X_train_teams, y_train_teams, X_test_teams, y_test_teams)\n",
    "\n",
    "# Fit the final neural network model with selected features\n",
    "scaler_teams = StandardScaler()\n",
    "X_train_teams_scaled_selected = scaler_teams.fit_transform(X_train_teams[selected_features_nn_teams])\n",
    "X_test_teams_scaled_selected = scaler_teams.transform(X_test_teams[selected_features_nn_teams])\n",
    "\n",
    "model_final_nn_teams = Sequential()\n",
    "model_final_nn_teams.add(Dense(64, input_dim=X_train_teams_scaled_selected.shape[1], activation='relu'))\n",
    "model_final_nn_teams.add(Dense(32, activation='relu'))\n",
    "model_final_nn_teams.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_final_nn_teams.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_final_nn_teams.fit(X_train_teams_scaled_selected, y_train_teams, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_prob_final_nn_teams = model_final_nn_teams.predict(X_test_teams_scaled_selected)\n",
    "y_pred_final_nn_teams = (y_pred_prob_final_nn_teams > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the final model\n",
    "accuracy_final_nn_teams = accuracy_score(y_test_teams, y_pred_final_nn_teams)\n",
    "report_final_nn_teams = classification_report(y_test_teams, y_pred_final_nn_teams)\n",
    "\n",
    "print(f'Selected Features: {selected_features_nn_teams}')\n",
    "print(f'Best Accuracy: {best_accuracy_nn_teams}')\n",
    "print('Final Model Accuracy:', accuracy_final_nn_teams)\n",
    "print('Classification Report:')\n",
    "print(report_final_nn_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Iterate through each dataset in the roles folder\n",
    "for position, dataset in datasets.items():\n",
    "    # Select only numeric columns\n",
    "    numeric_dataset = dataset.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Define the feature columns and target variable\n",
    "    features = numeric_dataset.drop(columns=['result'])\n",
    "    target = numeric_dataset['result']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Create the neural network model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred_prob = model.predict(X_test_scaled)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f'Position: {position}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print('Classification Report:')\n",
    "    print(report)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset to only include the 'top' position\n",
    "top_dataset = datasets['top']\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_dataset = top_dataset.select_dtypes(include=['number'])\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features = numeric_dataset.drop(columns=['result'])\n",
    "target = numeric_dataset['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Run backward selection\n",
    "selected_features_nn, best_accuracy_nn = backward_selection_nn(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Fit the final neural network model with selected features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_selected = scaler.fit_transform(X_train[selected_features_nn])\n",
    "X_test_scaled_selected = scaler.transform(X_test[selected_features_nn])\n",
    "\n",
    "model_final_nn = Sequential()\n",
    "model_final_nn.add(Dense(64, input_dim=X_train_scaled_selected.shape[1], activation='relu'))\n",
    "model_final_nn.add(Dense(32, activation='relu'))\n",
    "model_final_nn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_final_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_final_nn.fit(X_train_scaled_selected, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_prob_final_nn = model_final_nn.predict(X_test_scaled_selected)\n",
    "y_pred_final_nn = (y_pred_prob_final_nn > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the final model\n",
    "accuracy_final_nn_top = accuracy_score(y_test, y_pred_final_nn)\n",
    "report_final_nn_top = classification_report(y_test, y_pred_final_nn)\n",
    "\n",
    "print(f'Position: top')\n",
    "print(f'Selected Features: {selected_features_nn}')\n",
    "print(f'Best Accuracy: {best_accuracy_nn}')\n",
    "print('Final Model Accuracy:', accuracy_final_nn_top)\n",
    "print('Classification Report:')\n",
    "print(report_final_nn_top)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset to only include the 'jng' position\n",
    "jungle_dataset = datasets['jng']\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_dataset = jungle_dataset.select_dtypes(include=['number'])\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features = numeric_dataset.drop(columns=['result'])\n",
    "target = numeric_dataset['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Run backward selection\n",
    "selected_features_nn, best_accuracy_nn = backward_selection_nn(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Fit the final neural network model with selected features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_selected = scaler.fit_transform(X_train[selected_features_nn])\n",
    "X_test_scaled_selected = scaler.transform(X_test[selected_features_nn])\n",
    "\n",
    "model_final_nn = Sequential()\n",
    "model_final_nn.add(Dense(64, input_dim=X_train_scaled_selected.shape[1], activation='relu'))\n",
    "model_final_nn.add(Dense(32, activation='relu'))\n",
    "model_final_nn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_final_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_final_nn.fit(X_train_scaled_selected, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_prob_final_nn = model_final_nn.predict(X_test_scaled_selected)\n",
    "y_pred_final_nn = (y_pred_prob_final_nn > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the final model\n",
    "accuracy_final_nn_jungle = accuracy_score(y_test, y_pred_final_nn)\n",
    "report_final_nn_jungle = classification_report(y_test, y_pred_final_nn)\n",
    "\n",
    "print(f'Position: jungle')\n",
    "print(f'Selected Features: {selected_features_nn}')\n",
    "print(f'Best Accuracy: {best_accuracy_nn}')\n",
    "print('Final Model Accuracy:', accuracy_final_nn_jungle)\n",
    "print('Classification Report:')\n",
    "print(report_final_nn_jungle)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset to only include the 'mid' position\n",
    "mid_dataset = datasets['mid']\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_dataset = mid_dataset.select_dtypes(include=['number'])\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features = numeric_dataset.drop(columns=['result'])\n",
    "target = numeric_dataset['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Run backward selection\n",
    "selected_features_nn, best_accuracy_nn = backward_selection_nn(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Fit the final neural network model with selected features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_selected = scaler.fit_transform(X_train[selected_features_nn])\n",
    "X_test_scaled_selected = scaler.transform(X_test[selected_features_nn])\n",
    "\n",
    "model_final_nn = Sequential()\n",
    "model_final_nn.add(Dense(64, input_dim=X_train_scaled_selected.shape[1], activation='relu'))\n",
    "model_final_nn.add(Dense(32, activation='relu'))\n",
    "model_final_nn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_final_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_final_nn.fit(X_train_scaled_selected, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_prob_final_nn = model_final_nn.predict(X_test_scaled_selected)\n",
    "y_pred_final_nn = (y_pred_prob_final_nn > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the final model\n",
    "accuracy_final_nn_mid = accuracy_score(y_test, y_pred_final_nn)\n",
    "report_final_nn_mid = classification_report(y_test, y_pred_final_nn)\n",
    "\n",
    "print(f'Position: mid')\n",
    "print(f'Selected Features: {selected_features_nn}')\n",
    "print(f'Best Accuracy: {best_accuracy_nn}')\n",
    "print('Final Model Accuracy:', accuracy_final_nn_mid)\n",
    "print('Classification Report:')\n",
    "print(report_final_nn_mid)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset to only include the 'bot' position\n",
    "bot_dataset = datasets['bot']\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_dataset = bot_dataset.select_dtypes(include=['number'])\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features = numeric_dataset.drop(columns=['result'])\n",
    "target = numeric_dataset['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Run backward selection\n",
    "selected_features_nn, best_accuracy_nn = backward_selection_nn(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Fit the final neural network model with selected features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_selected = scaler.fit_transform(X_train[selected_features_nn])\n",
    "X_test_scaled_selected = scaler.transform(X_test[selected_features_nn])\n",
    "\n",
    "model_final_nn = Sequential()\n",
    "model_final_nn.add(Dense(64, input_dim=X_train_scaled_selected.shape[1], activation='relu'))\n",
    "model_final_nn.add(Dense(32, activation='relu'))\n",
    "model_final_nn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_final_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_final_nn.fit(X_train_scaled_selected, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_prob_final_nn = model_final_nn.predict(X_test_scaled_selected)\n",
    "y_pred_final_nn = (y_pred_prob_final_nn > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the final model\n",
    "accuracy_final_nn_bot = accuracy_score(y_test, y_pred_final_nn)\n",
    "report_final_nn_bot = classification_report(y_test, y_pred_final_nn)\n",
    "\n",
    "print(f'Position: bot')\n",
    "print(f'Selected Features: {selected_features_nn}')\n",
    "print(f'Best Accuracy: {best_accuracy_nn}')\n",
    "print('Final Model Accuracy:', accuracy_final_nn_bot)\n",
    "print('Classification Report:')\n",
    "print(report_final_nn_bot)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset to only include the 'sup' position\n",
    "support_dataset = datasets['sup']\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_dataset = support_dataset.select_dtypes(include=['number'])\n",
    "\n",
    "# Define the feature columns and target variable\n",
    "features = numeric_dataset.drop(columns=['result'])\n",
    "target = numeric_dataset['result']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Run backward selection\n",
    "selected_features_nn, best_accuracy_nn = backward_selection_nn(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Fit the final neural network model with selected features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_selected = scaler.fit_transform(X_train[selected_features_nn])\n",
    "X_test_scaled_selected = scaler.transform(X_test[selected_features_nn])\n",
    "\n",
    "model_final_nn = Sequential()\n",
    "model_final_nn.add(Dense(64, input_dim=X_train_scaled_selected.shape[1], activation='relu'))\n",
    "model_final_nn.add(Dense(32, activation='relu'))\n",
    "model_final_nn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_final_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_final_nn.fit(X_train_scaled_selected, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_prob_final_nn = model_final_nn.predict(X_test_scaled_selected)\n",
    "y_pred_final_nn = (y_pred_prob_final_nn > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the final model\n",
    "accuracy_final_nn_sup = accuracy_score(y_test, y_pred_final_nn)\n",
    "report_final_nn_sup = classification_report(y_test, y_pred_final_nn)\n",
    "\n",
    "print(f'Position: support')\n",
    "print(f'Selected Features: {selected_features_nn}')\n",
    "print(f'Best Accuracy: {best_accuracy_nn}')\n",
    "print('Final Model Accuracy:', accuracy_final_nn_sup)\n",
    "print('Classification Report:')\n",
    "print(report_final_nn_sup)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to store the accuracy scores of all models\n",
    "model_accuracies_complete = {\n",
    "    'Logistic Regression': log_accuracy,\n",
    "    'Random Forest': accuracy_rf_final,\n",
    "    'KNN': accuracy_knn_final,\n",
    "    'Neural Network': accuracy_final_nn,\n",
    "}\n",
    "\n",
    "# Find the model with the highest accuracy\n",
    "best_model = max(model_accuracies_complete, key=model_accuracies_complete.get)\n",
    "best_accuracy = model_accuracies_complete[best_model]\n",
    "\n",
    "print(f'The best model is: {best_model}')\n",
    "print(f'Accuracy: {best_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to store the accuracy scores of all models for team wins\n",
    "model_accuracies_teams = {\n",
    "    'Logistic Regression': accuracy_teams,\n",
    "    'Random Forest': accuracy_rf_final_teams,\n",
    "    'KNN': accuracy_knn_final_teams,\n",
    "    'Neural Network': accuracy_final_nn_teams,\n",
    "}\n",
    "\n",
    "# Find the model with the highest accuracy for team wins\n",
    "best_model_teams = max(model_accuracies_teams, key=model_accuracies_teams.get)\n",
    "best_accuracy_teams = model_accuracies_teams[best_model_teams]\n",
    "\n",
    "print(f'The best model for predicting team wins is: {best_model_teams}')\n",
    "print(f'Accuracy: {best_accuracy_teams}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to store the accuracy scores of all models for top lane wins\n",
    "model_accuracies_top = {\n",
    "    'Logistic Regression': best_models['top']['final_model_accuracy'],\n",
    "    'Random Forest': best_models_rf['top']['final_model_accuracy'],\n",
    "    'KNN': best_models_knn['top']['final_model_accuracy'],\n",
    "    'Neural Network': accuracy_final_nn_top,\n",
    "}\n",
    "\n",
    "# Find the model with the highest accuracy for top lane wins\n",
    "best_model_top = max(model_accuracies_top, key=model_accuracies_top.get)\n",
    "best_accuracy_top = model_accuracies_top[best_model_top]\n",
    "\n",
    "print(f'The best model for predicting top lane wins is: {best_model_top}')\n",
    "print(f'Accuracy: {best_accuracy_top}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to store the accuracy scores of all models for jungle wins\n",
    "model_accuracies_jungle = {\n",
    "    'Logistic Regression': best_models['jng']['final_model_accuracy'],\n",
    "    'Random Forest': best_models_rf['jng']['final_model_accuracy'],\n",
    "    'KNN': best_models_knn['jng']['final_model_accuracy'],\n",
    "    'Neural Network': accuracy_final_nn_jungle,\n",
    "}\n",
    "\n",
    "# Find the model with the highest accuracy for jungle wins\n",
    "best_model_jungle = max(model_accuracies_jungle, key=model_accuracies_jungle.get)\n",
    "best_accuracy_jungle = model_accuracies_jungle[best_model_jungle]\n",
    "\n",
    "print(f'The best model for predicting jungle wins is: {best_model_jungle}')\n",
    "print(f'Accuracy: {best_accuracy_jungle}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to store the accuracy scores of all models for mid lane wins\n",
    "model_accuracies_mid = {\n",
    "    'Logistic Regression': best_models['mid']['final_model_accuracy'],\n",
    "    'Random Forest': best_models_rf['mid']['final_model_accuracy'],\n",
    "    'KNN': best_models_knn['mid']['final_model_accuracy'],\n",
    "    'Neural Network': accuracy_final_nn_mid,\n",
    "}\n",
    "\n",
    "# Find the model with the highest accuracy for mid lane wins\n",
    "best_model_mid = max(model_accuracies_mid, key=model_accuracies_mid.get)\n",
    "best_accuracy_mid = model_accuracies_mid[best_model_mid]\n",
    "\n",
    "print(f'The best model for predicting mid lane wins is: {best_model_mid}')\n",
    "print(f'Accuracy: {best_accuracy_mid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to store the accuracy scores of all models for bot lane wins\n",
    "model_accuracies_bot = {\n",
    "    'Logistic Regression': best_models['bot']['final_model_accuracy'],\n",
    "    'Random Forest': best_models_rf['bot']['final_model_accuracy'],\n",
    "    'KNN': best_models_knn['bot']['final_model_accuracy'],\n",
    "    'Neural Network': accuracy_final_nn_bot,\n",
    "}\n",
    "\n",
    "# Find the model with the highest accuracy for bot lane wins\n",
    "best_model_bot = max(model_accuracies_bot, key=model_accuracies_bot.get)\n",
    "best_accuracy_bot = model_accuracies_bot[best_model_bot]\n",
    "\n",
    "print(f'The best model for predicting bot lane wins is: {best_model_bot}')\n",
    "print(f'Accuracy: {best_accuracy_bot}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to store the accuracy scores of all models for support wins\n",
    "model_accuracies_sup = {\n",
    "    'Logistic Regression': best_models['sup']['final_model_accuracy'],\n",
    "    'Random Forest': best_models_rf['sup']['final_model_accuracy'],\n",
    "    'KNN': best_models_knn['sup']['final_model_accuracy'],\n",
    "    'Neural Network': accuracy_final_nn_sup,\n",
    "}\n",
    "\n",
    "# Find the model with the highest accuracy for support wins\n",
    "best_model_sup = max(model_accuracies_sup, key=model_accuracies_sup.get)\n",
    "best_accuracy_sup = model_accuracies_sup[best_model_sup]\n",
    "\n",
    "print(f'The best model for predicting support wins is: {best_model_sup}')\n",
    "print(f'Accuracy: {best_accuracy_sup}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
